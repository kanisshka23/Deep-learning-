{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPl+BtHUt+DBXf0ySp7u9tM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kanisshka23/Deep-learning-/blob/main/Handwriting_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install easyocr transformers torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSWgxwn2IoNO",
        "outputId": "f8fbad59-ee60-4c6a-ba65-b5378d7bd8f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (10.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.24.0)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.8.30)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (281 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.3/281.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.1 pyclipper-1.3.0.post5 python-bidi-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "logging.getLogger(\"transformers.modeling_utils\").setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "fFuOCrw3MKke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8j3rEltJaxhQ",
        "outputId": "b5ea5721-187f-4776-8d85-f0fabf598526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "\n",
        "# Load a pre-trained NER model (fine-tuned on token classification)\n",
        "model_name = '/content/drive/MyDrive/finetunedner'\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "AqKNCufuMWIG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345d2092-836f-445f-ec52-8fcb8414ef5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import easyocr\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "image_path = '/content/sampleprescription.png'\n",
        "# Function to extract text from an image using EasyOCR\n",
        "def extract_text_from_image(image_path):\n",
        "    reader = easyocr.Reader(['en'])  # Initialize the reader for English\n",
        "    results = reader.readtext(image_path, detail=0)  # Extract text without bounding box details\n",
        "    extracted_text = ' '.join(results)  # Join the recognized words\n",
        "    return extracted_text\n",
        "\n",
        "# Load the pre-trained BioBERT model and tokenizer\n",
        "model_name = \"/content/drive/MyDrive/biobert\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForTokenClassification.from_pretrained(model_name)\n",
        "\n",
        "# Create a pipeline for Named Entity Recognition (NER)\n",
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, aggregation_strategy=\"simple\")\n",
        "\n",
        "# Function to classify medical terms in text\n",
        "def classify_medical_terms(text):\n",
        "    ner_results = nlp(text)\n",
        "    classified_terms = {\n",
        "        \"DRUG\": [],\n",
        "        \"DOSAGE\": [],\n",
        "        \"DURATION\": [],\n",
        "        \"TIME\": [],\n",
        "        \"PATIENT\": []\n",
        "    }\n",
        "\n",
        "    for entity in ner_results:\n",
        "        entity_label = entity['entity_group'].upper()\n",
        "\n",
        "        if \"DRUG\" in entity_label:\n",
        "            classified_terms[\"DRUG\"].append(entity['word'])\n",
        "        elif \"DOSE\" in entity_label or \"DOSAGE\" in entity_label:\n",
        "            classified_terms[\"DOSAGE\"].append(entity['word'])\n",
        "        elif \"DURATION\" in entity_label:\n",
        "            classified_terms[\"DURATION\"].append(entity['word'])\n",
        "        elif \"TIME\" in entity_label:\n",
        "            classified_terms[\"TIME\"].append(entity['word'])\n",
        "        elif \"PATIENT\" in entity_label:\n",
        "            classified_terms[\"PATIENT\"].append(entity['word'])\n",
        "\n",
        "    return classified_terms\n",
        "\n",
        "# Main function to run the pipeline\n",
        "def process_medical_prescription(image_path):\n",
        "    # Step 1: Extract text from image using EasyOCR\n",
        "    extracted_text = extract_text_from_image(image_path)\n",
        "    print(f\"Extracted Text: {extracted_text}\")\n",
        "\n",
        "    # Step 2: Classify medical terms using BioBERT\n",
        "    classified_terms = classify_medical_terms(extracted_text)\n",
        "\n",
        "    return classified_terms\n",
        "\n",
        "# Example usage:\n",
        "image_path = '/content/sampleprescription.png'  # Replace with your image path\n",
        "classified_data = process_medical_prescription(image_path)\n",
        "print(f\"Classified Medical Terms: {classified_data}\")"
      ],
      "metadata": {
        "id": "j6cYJfeJq8zj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03dd9417-7e53-4d76-827f-790daa497dcc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:easyocr.easyocr:Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted Text: DD FORM  1289 NOv 71 DOD PRESCRIPTION FOR (Full namo, address, & phone numbar)  (H under12, givo 3g0) Jebn&_Dee _ HMB USN Us.S Neverfergotten (DD 78) MEDICAL FACLIY DATE USS Never Forgotten (DD !78) 23 Jan 49 R (Superscription) gm Or ml: (Inscription) Ksebdanna 15 me Ampheaee 120 me (Subscription) mv #fL fuetwn> (Signe) Sm2 Ld 0.€ MFG: Wzeth  EXP DATE: 1loz LOTNO: P3ak06 FLLED BY: KMt Jack Z Frost LCDE ID, USIR 10072 R NUmbER SKGNATURE RANK AnO OEGREE EOMION OF JAN 80 MAY Be USEd  For Sin 0102-LF-012-6201 3984 Sv'\n",
            "Classified Medical Terms: {'DRUG': [], 'DOSAGE': [], 'DURATION': [], 'TIME': [], 'PATIENT': []}\n"
          ]
        }
      ]
    }
  ]
}